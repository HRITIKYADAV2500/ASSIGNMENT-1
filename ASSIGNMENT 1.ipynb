{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b680ac6",
   "metadata": {},
   "source": [
    "# QUESTION 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aadb495",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bs4\n",
    "!pip install requests\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "id": "801dc231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Page\n",
      "From today's featured article\n",
      "\n",
      "Personal tools\n",
      "\n"
     ]
    }
   ],
   "source": [
    "A1=requests.get(\"https://en.wikipedia.org/wiki/Main_Page\")\n",
    "soup=BeautifulSoup(A1.content)\n",
    "h1=soup.find('h1',class_=\"firstHeading mw-first-heading\")\n",
    "h2=soup.find('h2',class_=\"mp-h2\")\n",
    "h3=soup.find('h3',class_=\"vector-menu-heading\")\n",
    "print(h1.text)\n",
    "print(h2.text)\n",
    "print(h3.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbec5aa3",
   "metadata": {},
   "source": [
    "# QUESTION 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f439330",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bs4\n",
    "!pip install requests\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "id": "9116d05c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie</th>\n",
       "      <th>rating</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1TheShawshankRedemption1994</td>\n",
       "      <td>92</td>\n",
       "      <td>(1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2TheGodfather1972</td>\n",
       "      <td>92</td>\n",
       "      <td>(1972)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3TheDarkKnight2008</td>\n",
       "      <td>90</td>\n",
       "      <td>(2008)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4TheGodfatherPartII1974</td>\n",
       "      <td>90</td>\n",
       "      <td>(1974)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>512AngryMen1957</td>\n",
       "      <td>90</td>\n",
       "      <td>(1957)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96CitizenKane1941</td>\n",
       "      <td>83</td>\n",
       "      <td>(1941)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97MEineStadtsuchteinenMörder1931</td>\n",
       "      <td>83</td>\n",
       "      <td>(1931)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98LawrenceofArabia1962</td>\n",
       "      <td>83</td>\n",
       "      <td>(1962)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99NorthbyNorthwest1959</td>\n",
       "      <td>82</td>\n",
       "      <td>(1959)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100Vertigo1958</td>\n",
       "      <td>82</td>\n",
       "      <td>(1958)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               movie rating    year\n",
       "0        1TheShawshankRedemption1994     92  (1994)\n",
       "1                  2TheGodfather1972     92  (1972)\n",
       "2                 3TheDarkKnight2008     90  (2008)\n",
       "3            4TheGodfatherPartII1974     90  (1974)\n",
       "4                    512AngryMen1957     90  (1957)\n",
       "..                               ...    ...     ...\n",
       "95                 96CitizenKane1941     83  (1941)\n",
       "96  97MEineStadtsuchteinenMörder1931     83  (1931)\n",
       "97            98LawrenceofArabia1962     83  (1962)\n",
       "98            99NorthbyNorthwest1959     82  (1959)\n",
       "99                    100Vertigo1958     82  (1958)\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 863,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q=requests.get('https://www.imdb.com/chart/top/?ref_=nv_mv_250')\n",
    "soup=BeautifulSoup(Q.content)\n",
    "name=[]\n",
    "for i in soup.find_all('td',class_='titleColumn'):\n",
    "    name.append(i.text)\n",
    "year=[]\n",
    "for i in soup.find_all('span',class_=\"secondaryInfo\"):\n",
    "    year.append(i.text)\n",
    "rating=[]\n",
    "for i in soup.find_all('td',class_='ratingColumn imdbRating'):\n",
    "    rating.append(i.text)\n",
    "df=pd.DataFrame({\"movie\":name, \"rating\":rating, \"year\":year})\n",
    "df['movie']=df['movie'].str.replace(r'\\W',\"\")\n",
    "df['rating']=df['rating'].str.replace(r'\\W',\"\")\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f8902f",
   "metadata": {},
   "source": [
    "# QUESTION 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b60d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bs4\n",
    "!pip install requests\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "id": "95333e22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_name</th>\n",
       "      <th>rating</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1RamayanaTheLegendofPrinceRama1993</td>\n",
       "      <td>85</td>\n",
       "      <td>(1993)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2RocketryTheNambiEffect2022</td>\n",
       "      <td>84</td>\n",
       "      <td>(2022)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3777Charlie2022</td>\n",
       "      <td>84</td>\n",
       "      <td>(2022)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4Golmaal1979</td>\n",
       "      <td>84</td>\n",
       "      <td>(1979)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5Nayakan1987</td>\n",
       "      <td>84</td>\n",
       "      <td>(1987)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96KaakkaaMuttai2014</td>\n",
       "      <td>80</td>\n",
       "      <td>(2014)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97UstadHotel2012</td>\n",
       "      <td>80</td>\n",
       "      <td>(2012)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98TheeranAdhigaaramOndru2017</td>\n",
       "      <td>80</td>\n",
       "      <td>(2017)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99RangDeBasanti2006</td>\n",
       "      <td>80</td>\n",
       "      <td>(2006)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100Angoor1982</td>\n",
       "      <td>80</td>\n",
       "      <td>(1982)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            movie_name rating    year\n",
       "0   1RamayanaTheLegendofPrinceRama1993     85  (1993)\n",
       "1          2RocketryTheNambiEffect2022     84  (2022)\n",
       "2                      3777Charlie2022     84  (2022)\n",
       "3                         4Golmaal1979     84  (1979)\n",
       "4                         5Nayakan1987     84  (1987)\n",
       "..                                 ...    ...     ...\n",
       "95                 96KaakkaaMuttai2014     80  (2014)\n",
       "96                    97UstadHotel2012     80  (2012)\n",
       "97        98TheeranAdhigaaramOndru2017     80  (2017)\n",
       "98                 99RangDeBasanti2006     80  (2006)\n",
       "99                       100Angoor1982     80  (1982)\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 864,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q3=requests.get('https://www.imdb.com/india/top-rated-indian-movies/')\n",
    "soup=BeautifulSoup(q3.content)\n",
    "name=[]\n",
    "for i in soup.find_all('td',class_='titleColumn'):\n",
    "    name.append(i.text)\n",
    "rating=[]\n",
    "for i in soup.find_all('td',class_='ratingColumn imdbRating'):\n",
    "    rating.append(i.text)\n",
    "year=[]\n",
    "for i in soup.find_all('span',class_='secondaryInfo'):\n",
    "    year.append(i.text)\n",
    "df2=pd.DataFrame({'movie_name':name,'rating':rating,'year':year})\n",
    "df2['movie_name']=df2['movie_name'].str.replace(r'\\W',\"\")\n",
    "df2['rating']=df2['rating'].str.replace(r'\\W',\"\")\n",
    "df2.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93762716",
   "metadata": {},
   "source": [
    "# QUESTION 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f326a6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bs4\n",
    "!pip install requests\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "id": "a1e1f5dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME_OF_THE_PRESIDENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ShriRamNathKovindbirth1945TermofOffice25July20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ShriPranabMukherjee19352020TermofOffice25July2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SmtPratibhaDevisinghPatilbirth1934TermofOffice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DRAPJAbdulKalam19312015TermofOffice25July2002t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ShriKRNarayanan19202005TermofOffice25July1997t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DrShankarDayalSharma19181999TermofOffice25July...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ShriRVenkataraman19102009TermofOffice25July198...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GianiZailSingh19161994TermofOffice25July1982to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ShriNeelamSanjivaReddy19131996TermofOffice25Ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DrFakhruddinAliAhmed19051977TermofOffice24Augu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ShriVarahagiriVenkataGiri18941980TermofOffice3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DrZakirHusain18971969TermofOffice13May1967to3M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DrSarvepalliRadhakrishnan18881975TermofOffice1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DrRajendraPrasad18841963TermofOffice26January1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                NAME_OF_THE_PRESIDENT\n",
       "0   ShriRamNathKovindbirth1945TermofOffice25July20...\n",
       "1   ShriPranabMukherjee19352020TermofOffice25July2...\n",
       "2   SmtPratibhaDevisinghPatilbirth1934TermofOffice...\n",
       "3   DRAPJAbdulKalam19312015TermofOffice25July2002t...\n",
       "4   ShriKRNarayanan19202005TermofOffice25July1997t...\n",
       "5   DrShankarDayalSharma19181999TermofOffice25July...\n",
       "6   ShriRVenkataraman19102009TermofOffice25July198...\n",
       "7   GianiZailSingh19161994TermofOffice25July1982to...\n",
       "8   ShriNeelamSanjivaReddy19131996TermofOffice25Ju...\n",
       "9   DrFakhruddinAliAhmed19051977TermofOffice24Augu...\n",
       "10  ShriVarahagiriVenkataGiri18941980TermofOffice3...\n",
       "11  DrZakirHusain18971969TermofOffice13May1967to3M...\n",
       "12  DrSarvepalliRadhakrishnan18881975TermofOffice1...\n",
       "13  DrRajendraPrasad18841963TermofOffice26January1..."
      ]
     },
     "execution_count": 866,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q4=requests.get('https://presidentofindia.nic.in/former-presidents.htm')\n",
    "soup=BeautifulSoup(q4.content)\n",
    "president_name=[]\n",
    "for i in soup.find_all('div',class_='presidentListing'):\n",
    "    president_name.append(i.text)\n",
    "df3=pd.DataFrame({'NAME_OF_THE_PRESIDENT':president_name})\n",
    "df3['NAME_OF_THE_PRESIDENT']=df3['NAME_OF_THE_PRESIDENT'].str.replace(r'\\W',\"\")\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb29888",
   "metadata": {},
   "source": [
    "# QUESTION 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c847c68",
   "metadata": {},
   "source": [
    "FIRST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2fbf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bs4\n",
    "!pip install requests\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "id": "ab3ddda8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team</th>\n",
       "      <th>matches</th>\n",
       "      <th>points</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>23</td>\n",
       "      <td>2,670</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>England</td>\n",
       "      <td>30</td>\n",
       "      <td>3,400</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Australia</td>\n",
       "      <td>32</td>\n",
       "      <td>3,572</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>35</td>\n",
       "      <td>3,866</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>22</td>\n",
       "      <td>2,354</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>24</td>\n",
       "      <td>2,392</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>30</td>\n",
       "      <td>2,753</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>30</td>\n",
       "      <td>2,677</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>19</td>\n",
       "      <td>1,380</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>41</td>\n",
       "      <td>2,902</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           team matches points rating\n",
       "0   New Zealand      23  2,670    116\n",
       "1       England      30  3,400    113\n",
       "2     Australia      32  3,572    112\n",
       "3         India      35  3,866    110\n",
       "4      Pakistan      22  2,354    107\n",
       "5  South Africa      24  2,392    100\n",
       "6    Bangladesh      30  2,753     92\n",
       "7     Sri Lanka      30  2,677     89\n",
       "8   Afghanistan      19  1,380     73\n",
       "9   West Indies      41  2,902     71"
      ]
     },
     "execution_count": 867,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q5=requests.get('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')\n",
    "soup=BeautifulSoup(q5.content)\n",
    "team=[]\n",
    "for i in soup.find_all('span',class_='u-hide-phablet'):\n",
    "    team.append(i.text)\n",
    "df4=pd.DataFrame({'team':team})\n",
    "rating=[]\n",
    "for i in soup.find_all('td',class_=\"table-body__cell u-text-right rating\"):\n",
    "    rating.append(i.text)\n",
    "df_new=pd.DataFrame({'rating':rating})\n",
    "rat=[]\n",
    "for i in soup.find_all('td',class_='rankings-block__banner--rating u-text-right'):\n",
    "    rat.append(i.text)    \n",
    "rat1=pd.DataFrame({'rating':rat})\n",
    "rat1['rating']=rat1['rating'].str.replace(r'\\W',\"\")\n",
    "r=pd.concat([rat1,df_new],ignore_index=True)\n",
    "\n",
    "matches=[]\n",
    "for i in soup.find_all('td',class_='table-body__cell u-center-text'):\n",
    "    matches.append(i.text)\n",
    "m=pd.DataFrame({'matches':matches})\n",
    "matches=m.iloc[[0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36],[0]]\n",
    "matcha=[]\n",
    "for i in soup.find_all('td',class_='rankings-block__banner--matches'):\n",
    "    matcha.append(i.text)\n",
    "match1=pd.DataFrame({'matches':matcha})\n",
    "match=pd.concat([match1,matches],ignore_index=True)\n",
    "point=[]\n",
    "for i in soup.find_all('td',class_='rankings-block__banner--points'):\n",
    "    point.append(i.text)\n",
    "pda=pd.DataFrame({'points':point})\n",
    "points=[]\n",
    "for i in soup.find_all('td',class_='table-body__cell u-center-text'):\n",
    "    points.append(i.text)\n",
    "pda1=pd.DataFrame({'points':points})\n",
    "pdaa=pda1.iloc[[1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31,33,35,37],[0]]\n",
    "pt=pd.concat([pda,pdaa],ignore_index=True)\n",
    "r1=pd.merge(df4,match,right_index=True,left_index=True)\n",
    "r2=pd.merge(r1,pt,right_index=True,left_index=True)\n",
    "r3=pd.merge(r2,r,right_index=True,left_index=True)\n",
    "r3.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ca1cdf",
   "metadata": {},
   "source": [
    "SECOND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc283dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bs4\n",
    "!pip install requests\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "id": "7303d585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batsman</th>\n",
       "      <th>team</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>PAK890</td>\n",
       "      <td>890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ImamulHaq</td>\n",
       "      <td>NZ760</td>\n",
       "      <td>779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RassievanderDussen</td>\n",
       "      <td>BAN372</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>QuintondeKock</td>\n",
       "      <td>PAK890</td>\n",
       "      <td>759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DavidWarner</td>\n",
       "      <td>NZ760</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SteveSmith</td>\n",
       "      <td>BAN372</td>\n",
       "      <td>719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>JonnyBairstow</td>\n",
       "      <td>PAK</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ViratKohli</td>\n",
       "      <td>SA</td>\n",
       "      <td>707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RohitSharma</td>\n",
       "      <td>SA</td>\n",
       "      <td>704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KaneWilliamson</td>\n",
       "      <td>AUS</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              batsman    team rank\n",
       "0          Babar Azam  PAK890  890\n",
       "1           ImamulHaq   NZ760  779\n",
       "2  RassievanderDussen  BAN372  766\n",
       "3       QuintondeKock  PAK890  759\n",
       "4         DavidWarner   NZ760  747\n",
       "5          SteveSmith  BAN372  719\n",
       "6       JonnyBairstow     PAK  710\n",
       "7          ViratKohli      SA  707\n",
       "8         RohitSharma      SA  704\n",
       "9      KaneWilliamson     AUS  701"
      ]
     },
     "execution_count": 868,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q5b=requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi')\n",
    "soup=BeautifulSoup(q5b.content)\n",
    "batsman=[]\n",
    "for i in soup.find_all('div',class_='rankings-block__banner--name'):\n",
    "    batsman.append(i.text)\n",
    "bat=pd.DataFrame({'batsman':batsman})\n",
    "b=bat.head(1)\n",
    "batmans=[]\n",
    "for i in soup.find_all('td',class_='table-body__cell name'):\n",
    "    batmans.append(i.text)\n",
    "bats=pd.DataFrame({'batsman':batmans})\n",
    "bats['batsman']=bats['batsman'].str.replace(r'\\W',\"\")\n",
    "batter=pd.concat([b,bats],ignore_index=True)\n",
    "team=[]\n",
    "for i in soup.find_all('div',class_='rankings-block__banner--nationality'):\n",
    "    team.append(i.text)\n",
    "t=pd.DataFrame({'team':team})\n",
    "t['team']=t['team'].str.replace(r'\\W',\"\")\n",
    "teams=[]\n",
    "for i in soup.find_all('span',class_='table-body__logo-text'):\n",
    "    teams.append(i.text)\n",
    "te=pd.DataFrame({'team':teams})\n",
    "teamss=pd.concat([t,te],ignore_index=True)\n",
    "rank=[]\n",
    "for i in soup.find_all('div',class_='rankings-block__banner--rating'):\n",
    "    rank.append(i.text)\n",
    "r=pd.DataFrame({'rank':rank})\n",
    "rr=r.head(1)\n",
    "ranks=[]\n",
    "for i in soup.find_all('td',class_='table-body__cell u-text-right rating'):\n",
    "    ranks.append(i.text)\n",
    "ra=pd.DataFrame({'rank':ranks})\n",
    "ratting=pd.concat([rr,ra],ignore_index=True)\n",
    "p1=pd.merge(batter,teamss,right_index=True,left_index=True)\n",
    "p2=pd.merge(p1,ratting,right_index=True,left_index=True)\n",
    "p2.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea228f49",
   "metadata": {},
   "source": [
    "THIRD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44df95f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bs4\n",
    "!pip install requests\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "id": "7d766b66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>players</th>\n",
       "      <th>teams</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>[NZ, 760]</td>\n",
       "      <td>760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JoshHazlewood</td>\n",
       "      <td>[AUS]</td>\n",
       "      <td>727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MitchellStarc</td>\n",
       "      <td>[AUS]</td>\n",
       "      <td>665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ShaheenAfridi</td>\n",
       "      <td>[PAK]</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MattHenry</td>\n",
       "      <td>[NZ]</td>\n",
       "      <td>656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AdamZampa</td>\n",
       "      <td>[AUS]</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MehediHasan</td>\n",
       "      <td>[BAN]</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MujeebUrRahman</td>\n",
       "      <td>[AFG]</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MustafizurRahman</td>\n",
       "      <td>[BAN]</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RashidKhan</td>\n",
       "      <td>[AFG]</td>\n",
       "      <td>635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            players      teams rank\n",
       "0       Trent Boult  [NZ, 760]  760\n",
       "1     JoshHazlewood      [AUS]  727\n",
       "2     MitchellStarc      [AUS]  665\n",
       "3     ShaheenAfridi      [PAK]  661\n",
       "4         MattHenry       [NZ]  656\n",
       "5         AdamZampa      [AUS]  655\n",
       "6       MehediHasan      [BAN]  655\n",
       "7    MujeebUrRahman      [AFG]  650\n",
       "8  MustafizurRahman      [BAN]  640\n",
       "9        RashidKhan      [AFG]  635"
      ]
     },
     "execution_count": 869,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q5c=requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi')\n",
    "soup=BeautifulSoup(q5c.content)\n",
    "p=[]\n",
    "for i in soup.find_all('div',class_='rankings-block__banner--name'):\n",
    "    p.append(i.text)\n",
    "pf=pd.DataFrame({'player':p})\n",
    "p2=pf.loc[1]\n",
    "p3=pd.DataFrame({'players':p2})\n",
    "ps=[]\n",
    "for i in soup.find_all('td',class_='table-body__cell name'):\n",
    "    ps.append(i.text)\n",
    "psf=pd.DataFrame({'players':ps})\n",
    "psf['players']=psf['players'].str.replace(r'\\W',\"\")\n",
    "psm=psf.loc[9:19]\n",
    "player=pd.concat([p3,psm],ignore_index=True)\n",
    "t=[]\n",
    "for i in soup.find_all('div',class_='rankings-block__banner--nationality'):\n",
    "    t.append(i.text.split())\n",
    "tf=pd.DataFrame({'teams':t})\n",
    "t2=tf.loc[1]\n",
    "t3=pd.DataFrame({'teams':t2})\n",
    "ts=[]\n",
    "for i in soup.find_all('td',class_='table-body__cell nationality-logo'):\n",
    "    ts.append(i.text.split())\n",
    "tsf=pd.DataFrame({'teams':ts})\n",
    "tsfm=tsf.loc[9:19]\n",
    "teams=pd.concat([t3,tsfm],ignore_index=True)\n",
    "r=[]\n",
    "for i in soup.find_all('div',class_='rankings-block__banner--rating'):\n",
    "    r.append(i.text)\n",
    "rf=pd.DataFrame({'rank':r})\n",
    "rf2=rf.loc[1]\n",
    "rf3=pd.DataFrame({'rank':rf2})\n",
    "rs=[]\n",
    "for i in soup.find_all('td',class_='table-body__cell u-text-right rating'):\n",
    "    rs.append(i.text)\n",
    "rsf=pd.DataFrame({'rank':rs})\n",
    "rs2=rsf.loc[9:17]\n",
    "rank=pd.concat([rf3,rs2],ignore_index=True)\n",
    "bow=pd.merge(player,teams,right_index=True,left_index=True)\n",
    "bow1=pd.merge(bow,rank,right_index=True,left_index=True)\n",
    "bow1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd5dd9f",
   "metadata": {},
   "source": [
    "# QUESTION 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9ac6b1",
   "metadata": {},
   "source": [
    "FIRST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f438e98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bs4\n",
    "!pip install requests\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "id": "565eee06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team</th>\n",
       "      <th>matches</th>\n",
       "      <th>points</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Australia]</td>\n",
       "      <td>18</td>\n",
       "      <td>3,061</td>\n",
       "      <td>[170]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[South, Africa]</td>\n",
       "      <td>26</td>\n",
       "      <td>3,098</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[England]</td>\n",
       "      <td>25</td>\n",
       "      <td>2,904</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[India]</td>\n",
       "      <td>27</td>\n",
       "      <td>2,820</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[New, Zealand]</td>\n",
       "      <td>24</td>\n",
       "      <td>2,425</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[West, Indies]</td>\n",
       "      <td>24</td>\n",
       "      <td>2,334</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[Bangladesh]</td>\n",
       "      <td>8</td>\n",
       "      <td>932</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[Thailand]</td>\n",
       "      <td>24</td>\n",
       "      <td>572</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[Pakistan]</td>\n",
       "      <td>8</td>\n",
       "      <td>1,519</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[Sri, Lanka]</td>\n",
       "      <td>14</td>\n",
       "      <td>353</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[Ireland]</td>\n",
       "      <td>9</td>\n",
       "      <td>548</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[Netherlands]</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               team matches points rating\n",
       "0       [Australia]      18  3,061  [170]\n",
       "1   [South, Africa]      26  3,098    119\n",
       "2         [England]      25  2,904    116\n",
       "3           [India]      27  2,820    104\n",
       "4    [New, Zealand]      24  2,425    101\n",
       "5    [West, Indies]      24  2,334     97\n",
       "6      [Bangladesh]       8    932     78\n",
       "7        [Thailand]      24    572     72\n",
       "8        [Pakistan]       8  1,519     63\n",
       "9      [Sri, Lanka]      14    353     44\n",
       "10        [Ireland]       9    548     39\n",
       "11    [Netherlands]       8      0      0"
      ]
     },
     "execution_count": 870,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q6=requests.get('https://www.icc-cricket.com/rankings/womens/team-rankings/odi')\n",
    "soup=BeautifulSoup(q6.content)\n",
    "ts=[]\n",
    "for i in soup.find_all('span',class_='u-hide-phablet'):\n",
    "    ts.append(i.text.split())\n",
    "tsf=pd.DataFrame({'team':ts})\n",
    "ms=[]\n",
    "for i in soup.find_all('td',class_='table-body__cell u-center-text'):\n",
    "    ms.append(i.text)\n",
    "msf=pd.DataFrame({'matches':ms})\n",
    "match=msf.iloc[[0,2,4,6,8.10,12,14,16,18,20,22],[0]]\n",
    "m=[]\n",
    "for i in soup.find_all('td',class_='rankings-block__banner--matches'):\n",
    "    m.append(i.text)\n",
    "mf=pd.DataFrame({'matches':m})\n",
    "matches=pd.concat([mf,match],ignore_index=True)\n",
    "p=[]\n",
    "for i in soup.find_all('td',class_='rankings-block__banner--points'):\n",
    "    p.append(i.text)\n",
    "pf=pd.DataFrame({'points':p})\n",
    "ps=msf.iloc[[1,3,5,7,9,11,13,15,17,19,21,23],[0]]\n",
    "ps.rename(columns={'matches':'points'},inplace=True)\n",
    "point=pd.concat([pf,ps],ignore_index=True)\n",
    "r=[]\n",
    "for i in soup.find_all('td',class_='rankings-block__banner--rating u-text-right'):\n",
    "    r.append(i.text.split())\n",
    "rf=pd.DataFrame({'rating':r})\n",
    "rs=[]\n",
    "for i in soup.find_all('td',class_='table-body__cell u-text-right rating'):\n",
    "    rs.append(i.text)\n",
    "rsf=pd.DataFrame({'rating':rs})\n",
    "rating=pd.concat([rf,rsf],ignore_index=True)\n",
    "wt=pd.merge(tsf,matches,right_index=True,left_index=True)\n",
    "wt1=pd.merge(wt,point,right_index=True,left_index=True)\n",
    "wt2=pd.merge(wt1,rating,right_index=True,left_index=True)\n",
    "wt2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562db769",
   "metadata": {},
   "source": [
    "SECOND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92d97eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bs4\n",
    "!pip install requests\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "id": "80838868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>players</th>\n",
       "      <th>teams</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>AUS785</td>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BethMooney</td>\n",
       "      <td>AUS</td>\n",
       "      <td>749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LauraWolvaardt</td>\n",
       "      <td>SA</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NatalieSciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HarmanpreetKaur</td>\n",
       "      <td>IND</td>\n",
       "      <td>716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SmritiMandhana</td>\n",
       "      <td>IND</td>\n",
       "      <td>714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MegLanning</td>\n",
       "      <td>AUS</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RachaelHaynes</td>\n",
       "      <td>AUS</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AmySatterthwaite</td>\n",
       "      <td>NZ</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ChamariAthapaththu</td>\n",
       "      <td>SL</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              players   teams rating\n",
       "0        Alyssa Healy  AUS785    785\n",
       "1          BethMooney     AUS    749\n",
       "2      LauraWolvaardt      SA    732\n",
       "3       NatalieSciver     ENG    725\n",
       "4     HarmanpreetKaur     IND    716\n",
       "5      SmritiMandhana     IND    714\n",
       "6          MegLanning     AUS    710\n",
       "7       RachaelHaynes     AUS    701\n",
       "8    AmySatterthwaite      NZ    661\n",
       "9  ChamariAthapaththu      SL    655"
      ]
     },
     "execution_count": 871,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q6c=requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi')\n",
    "soup=BeautifulSoup(q6c.content)\n",
    "p=[]\n",
    "for i in soup.find_all('div',class_='rankings-block__banner--name'):\n",
    "    p.append(i.text)\n",
    "pf=pd.DataFrame({'players':p})\n",
    "pp=pf.head(1)\n",
    "ps=[]\n",
    "for i in soup.find_all('td',class_='table-body__cell name'):\n",
    "    ps.append(i.text)\n",
    "psf=pd.DataFrame({'players':ps})\n",
    "psf['players']=psf['players'].str.replace(r'\\W',\"\")\n",
    "players=pd.concat([pp,psf],ignore_index=True)\n",
    "t=[]\n",
    "for i in soup.find_all('div',class_='rankings-block__banner--nationality'):\n",
    "    t.append(i.text)\n",
    "tf=pd.DataFrame({'teams':t})\n",
    "tf['teams']=tf['teams'].str.replace(r'\\W',\"\")\n",
    "tt=tf.head(1)\n",
    "ts=[]\n",
    "for i in soup.find_all('span',class_='table-body__logo-text'):\n",
    "    ts.append(i.text)\n",
    "tsf=pd.DataFrame({'teams':ts})\n",
    "tsf['teams']=tsf['teams'].str.replace(r'\\W',\"\")\n",
    "teams=pd.concat([tt,tsf],ignore_index=True)\n",
    "r=[]\n",
    "for i in soup.find_all('div',class_='rankings-block__banner--rating'):\n",
    "    r.append(i.text)\n",
    "rf=pd.DataFrame({'rating':r})\n",
    "rf['rating']=rf['rating'].str.replace(r'\\W',\"\")\n",
    "rft=rf.head(1)\n",
    "rs=[]\n",
    "for i in soup.find_all('td',class_='table-body__cell u-text-right rating'):\n",
    "    rs.append(i.text)\n",
    "rsf=pd.DataFrame({'rating':rs})\n",
    "rank=pd.concat([rft,rsf],ignore_index=True)\n",
    "w=pd.merge(players,teams,right_index=True,left_index=True)\n",
    "w1=pd.merge(w,rank,right_index=True,left_index=True)\n",
    "w1.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf27f3f",
   "metadata": {},
   "source": [
    "THIRD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1994c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bs4\n",
    "!pip install requests\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "id": "aeb77a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>players</th>\n",
       "      <th>teams</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sophie Ecclestone</td>\n",
       "      <td>ENG739</td>\n",
       "      <td>739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JessJonassen</td>\n",
       "      <td>AUS</td>\n",
       "      <td>725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MeganSchutt</td>\n",
       "      <td>AUS</td>\n",
       "      <td>722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ShabnimIsmail</td>\n",
       "      <td>SA</td>\n",
       "      <td>722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JhulanGoswami</td>\n",
       "      <td>IND</td>\n",
       "      <td>698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HayleyMatthews</td>\n",
       "      <td>WI</td>\n",
       "      <td>671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KateCross</td>\n",
       "      <td>ENG</td>\n",
       "      <td>657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AyabongaKhaka</td>\n",
       "      <td>SA</td>\n",
       "      <td>634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RajeshwariGayakwad</td>\n",
       "      <td>IND</td>\n",
       "      <td>617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MarizanneKapp</td>\n",
       "      <td>SA</td>\n",
       "      <td>598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              players   teams rating\n",
       "0   Sophie Ecclestone  ENG739    739\n",
       "1        JessJonassen     AUS    725\n",
       "2         MeganSchutt     AUS    722\n",
       "3       ShabnimIsmail      SA    722\n",
       "4       JhulanGoswami     IND    698\n",
       "5      HayleyMatthews      WI    671\n",
       "6           KateCross     ENG    657\n",
       "7       AyabongaKhaka      SA    634\n",
       "8  RajeshwariGayakwad     IND    617\n",
       "9       MarizanneKapp      SA    598"
      ]
     },
     "execution_count": 872,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf1=pf.iloc[1]\n",
    "pf2=pd.DataFrame({'players':pf1})\n",
    "psf2=psf.iloc[9:18]\n",
    "players=pd.concat([pf2,psf2],ignore_index=True)\n",
    "tf2=tf.iloc[1]\n",
    "tf3=pd.DataFrame({'teams':tf2})\n",
    "tn=tsf.iloc[9:18]\n",
    "team=pd.concat([tf3,tn],ignore_index=True)\n",
    "rf2=rf.iloc[1]\n",
    "rf3=pd.DataFrame({'rating':rf2})\n",
    "rsf2=rsf.iloc[9:18]\n",
    "rating=pd.concat([rf3,rsf2],ignore_index=True)\n",
    "table=pd.merge(players,team,right_index=True,left_index=True)\n",
    "table1=pd.merge(table,rating,right_index=True,left_index=True)\n",
    "table1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f64141",
   "metadata": {},
   "source": [
    "# QUESTION 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc09f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bs4\n",
    "!pip install requests\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "id": "e04d6fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>heading</th>\n",
       "      <th>links</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dow sheds more than 100 points as investors di...</td>\n",
       "      <td>https://www.cnbc.com/2022/11/29/stock-market-f...</td>\n",
       "      <td>11 min ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Elon Musk says the Fed must cut rates ‘immedia...</td>\n",
       "      <td>https://www.cnbc.com/2022/11/30/elon-musk-says...</td>\n",
       "      <td>11 min ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As Wall Street gets bearish, these global stoc...</td>\n",
       "      <td>/pro/</td>\n",
       "      <td>23 min ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Singapore's deputy prime minister calls FTX lo...</td>\n",
       "      <td>https://www.cnbc.com/2022/11/30/ftx-loss-is-di...</td>\n",
       "      <td>23 min ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Transitory inflation talk is back. But economi...</td>\n",
       "      <td>https://www.cnbc.com/2022/11/30/transitory-inf...</td>\n",
       "      <td>5 hours ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Biden's Inflation Reduction Act makes green hy...</td>\n",
       "      <td>https://www.cnbc.com/2022/11/30/the-ira-makes-...</td>\n",
       "      <td>5 hours ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Goldman Sachs' Currie says oil stocks are trad...</td>\n",
       "      <td>/pro/</td>\n",
       "      <td>2 hours ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>These are shaping up to be the best and worst ...</td>\n",
       "      <td>https://www.cnbc.com/2022/11/29/dubai-miami-to...</td>\n",
       "      <td>2 hours ago</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             heading  \\\n",
       "0  Dow sheds more than 100 points as investors di...   \n",
       "1  Elon Musk says the Fed must cut rates ‘immedia...   \n",
       "2  As Wall Street gets bearish, these global stoc...   \n",
       "3  Singapore's deputy prime minister calls FTX lo...   \n",
       "4  Transitory inflation talk is back. But economi...   \n",
       "5  Biden's Inflation Reduction Act makes green hy...   \n",
       "6  Goldman Sachs' Currie says oil stocks are trad...   \n",
       "7  These are shaping up to be the best and worst ...   \n",
       "\n",
       "                                               links         time  \n",
       "0  https://www.cnbc.com/2022/11/29/stock-market-f...   11 min ago  \n",
       "1  https://www.cnbc.com/2022/11/30/elon-musk-says...   11 min ago  \n",
       "2                                              /pro/   23 min ago  \n",
       "3  https://www.cnbc.com/2022/11/30/ftx-loss-is-di...   23 min ago  \n",
       "4  https://www.cnbc.com/2022/11/30/transitory-inf...  5 hours ago  \n",
       "5  https://www.cnbc.com/2022/11/30/the-ira-makes-...  5 hours ago  \n",
       "6                                              /pro/  2 hours ago  \n",
       "7  https://www.cnbc.com/2022/11/29/dubai-miami-to...  2 hours ago  "
      ]
     },
     "execution_count": 873,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page=requests.get('https://www.cnbc.com/world/?region=world')\n",
    "soup=BeautifulSoup(page.content)\n",
    "head=[]\n",
    "for i in soup.find_all('div',class_='RiverHeadline-headline RiverHeadline-hasThumbnail'):\n",
    "    head.append(i.text)\n",
    "time=[]\n",
    "for i in soup.find_all('span',class_='RiverByline-datePublished'):\n",
    "    time.append(i.text)\n",
    "t=pd.DataFrame({'time':time})\n",
    "\n",
    "data=soup.find_all('div',class_='RiverHeadline-headline RiverHeadline-hasThumbnail')\n",
    "link=[]\n",
    "for i in data:\n",
    "    tlink=i.find('a')['href']\n",
    "    link.append(tlink)\n",
    "news=pd.DataFrame({'heading':head,'links':link})\n",
    "News=pd.merge(news,t,right_index=True,left_index=True)\n",
    "News"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90954ae",
   "metadata": {},
   "source": [
    "# QUESTION 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ce55fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bs4\n",
    "!pip install requests\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "id": "9656d16c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOWNLOADS</th>\n",
       "      <th>AUTHORS</th>\n",
       "      <th>DATE</th>\n",
       "      <th>LINK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reward is enough</td>\n",
       "      <td>Silver, David, Singh, Satinder, Precup, Doina,...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Making sense of raw input</td>\n",
       "      <td>Evans, Richard, Bošnjak, Matko and 5 more</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Law and logic: A review from an argumentation ...</td>\n",
       "      <td>Prakken, Henry, Sartor, Giovanni</td>\n",
       "      <td>October 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Creativity and artificial intelligence</td>\n",
       "      <td>Boden, Margaret A.</td>\n",
       "      <td>August 1998</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Artificial cognition for social human–robot in...</td>\n",
       "      <td>Lemaignan, Séverin, Warnier, Mathieu and 3 more</td>\n",
       "      <td>June 2017</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Explanation in artificial intelligence: Insigh...</td>\n",
       "      <td>Miller, Tim</td>\n",
       "      <td>February 2019</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Making sense of sensory input</td>\n",
       "      <td>Evans, Richard, Hernández-Orallo, José and 3 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Conflict-based search for optimal multi-agent ...</td>\n",
       "      <td>Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...</td>\n",
       "      <td>February 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Between MDPs and semi-MDPs: A framework for te...</td>\n",
       "      <td>Sutton, Richard S., Precup, Doina, Singh, Sati...</td>\n",
       "      <td>August 1999</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Hanabi challenge: A new frontier for AI re...</td>\n",
       "      <td>Bard, Nolan, Foerster, Jakob N. and 13 more</td>\n",
       "      <td>March 2020</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Evaluating XAI: A comparison of rule-based and...</td>\n",
       "      <td>van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...</td>\n",
       "      <td>February 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Argumentation in artificial intelligence</td>\n",
       "      <td>Bench-Capon, T.J.M., Dunne, Paul E.</td>\n",
       "      <td>October 2007</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Algorithms for computing strategies in two-pla...</td>\n",
       "      <td>Bošanský, Branislav, Lisý, Viliam and 3 more</td>\n",
       "      <td>August 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Multiple object tracking: A literature review</td>\n",
       "      <td>Luo, Wenhan, Xing, Junliang and 4 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Selection of relevant features and examples in...</td>\n",
       "      <td>Blum, Avrim L., Langley, Pat</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A survey of inverse reinforcement learning: Ch...</td>\n",
       "      <td>Arora, Saurabh, Doshi, Prashant</td>\n",
       "      <td>August 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Explaining individual predictions when feature...</td>\n",
       "      <td>Aas, Kjersti, Jullum, Martin, Løland, Anders</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A review of possible effects of cognitive bias...</td>\n",
       "      <td>Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...</td>\n",
       "      <td>June 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Integrating social power into the decision-mak...</td>\n",
       "      <td>Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.</td>\n",
       "      <td>December 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>“That's (not) the output I expected!” On the r...</td>\n",
       "      <td>Riveiro, Maria, Thill, Serge</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Explaining black-box classifiers using post-ho...</td>\n",
       "      <td>Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...</td>\n",
       "      <td>May 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Algorithm runtime prediction: Methods &amp; evalua...</td>\n",
       "      <td>Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...</td>\n",
       "      <td>January 2014</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Wrappers for feature subset selection</td>\n",
       "      <td>Kohavi, Ron, John, George H.</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Commonsense visual sensemaking for autonomous ...</td>\n",
       "      <td>Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Quantum computation, quantum theory and AI</td>\n",
       "      <td>Ying, Mingsheng</td>\n",
       "      <td>February 2010</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            DOWNLOADS  \\\n",
       "0                                    Reward is enough   \n",
       "1                           Making sense of raw input   \n",
       "2   Law and logic: A review from an argumentation ...   \n",
       "3              Creativity and artificial intelligence   \n",
       "4   Artificial cognition for social human–robot in...   \n",
       "5   Explanation in artificial intelligence: Insigh...   \n",
       "6                       Making sense of sensory input   \n",
       "7   Conflict-based search for optimal multi-agent ...   \n",
       "8   Between MDPs and semi-MDPs: A framework for te...   \n",
       "9   The Hanabi challenge: A new frontier for AI re...   \n",
       "10  Evaluating XAI: A comparison of rule-based and...   \n",
       "11           Argumentation in artificial intelligence   \n",
       "12  Algorithms for computing strategies in two-pla...   \n",
       "13      Multiple object tracking: A literature review   \n",
       "14  Selection of relevant features and examples in...   \n",
       "15  A survey of inverse reinforcement learning: Ch...   \n",
       "16  Explaining individual predictions when feature...   \n",
       "17  A review of possible effects of cognitive bias...   \n",
       "18  Integrating social power into the decision-mak...   \n",
       "19  “That's (not) the output I expected!” On the r...   \n",
       "20  Explaining black-box classifiers using post-ho...   \n",
       "21  Algorithm runtime prediction: Methods & evalua...   \n",
       "22              Wrappers for feature subset selection   \n",
       "23  Commonsense visual sensemaking for autonomous ...   \n",
       "24         Quantum computation, quantum theory and AI   \n",
       "\n",
       "                                              AUTHORS            DATE  \\\n",
       "0   Silver, David, Singh, Satinder, Precup, Doina,...    October 2021   \n",
       "1           Evans, Richard, Bošnjak, Matko and 5 more    October 2021   \n",
       "2                   Prakken, Henry, Sartor, Giovanni     October 2015   \n",
       "3                                 Boden, Margaret A.      August 1998   \n",
       "4     Lemaignan, Séverin, Warnier, Mathieu and 3 more       June 2017   \n",
       "5                                        Miller, Tim    February 2019   \n",
       "6   Evans, Richard, Hernández-Orallo, José and 3 more      April 2021   \n",
       "7   Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...   February 2015   \n",
       "8   Sutton, Richard S., Precup, Doina, Singh, Sati...     August 1999   \n",
       "9         Bard, Nolan, Foerster, Jakob N. and 13 more      March 2020   \n",
       "10  van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...   February 2021   \n",
       "11               Bench-Capon, T.J.M., Dunne, Paul E.     October 2007   \n",
       "12       Bošanský, Branislav, Lisý, Viliam and 3 more     August 2016   \n",
       "13             Luo, Wenhan, Xing, Junliang and 4 more      April 2021   \n",
       "14                      Blum, Avrim L., Langley, Pat    December 1997   \n",
       "15                   Arora, Saurabh, Doshi, Prashant      August 2021   \n",
       "16      Aas, Kjersti, Jullum, Martin, Løland, Anders   September 2021   \n",
       "17  Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...       June 2021   \n",
       "18    Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.    December 2016   \n",
       "19                      Riveiro, Maria, Thill, Serge   September 2021   \n",
       "20  Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...        May 2021   \n",
       "21  Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...    January 2014   \n",
       "22                      Kohavi, Ron, John, George H.    December 1997   \n",
       "23  Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...    October 2021   \n",
       "24                                   Ying, Mingsheng    February 2010   \n",
       "\n",
       "                                                 LINK  \n",
       "0   https://www.sciencedirect.com/science/article/...  \n",
       "1   https://www.sciencedirect.com/science/article/...  \n",
       "2   https://www.sciencedirect.com/science/article/...  \n",
       "3   https://www.sciencedirect.com/science/article/...  \n",
       "4   https://www.sciencedirect.com/science/article/...  \n",
       "5   https://www.sciencedirect.com/science/article/...  \n",
       "6   https://www.sciencedirect.com/science/article/...  \n",
       "7   https://www.sciencedirect.com/science/article/...  \n",
       "8   https://www.sciencedirect.com/science/article/...  \n",
       "9   https://www.sciencedirect.com/science/article/...  \n",
       "10  https://www.sciencedirect.com/science/article/...  \n",
       "11  https://www.sciencedirect.com/science/article/...  \n",
       "12  https://www.sciencedirect.com/science/article/...  \n",
       "13  https://www.sciencedirect.com/science/article/...  \n",
       "14  https://www.sciencedirect.com/science/article/...  \n",
       "15  https://www.sciencedirect.com/science/article/...  \n",
       "16  https://www.sciencedirect.com/science/article/...  \n",
       "17  https://www.sciencedirect.com/science/article/...  \n",
       "18  https://www.sciencedirect.com/science/article/...  \n",
       "19  https://www.sciencedirect.com/science/article/...  \n",
       "20  https://www.sciencedirect.com/science/article/...  \n",
       "21  https://www.sciencedirect.com/science/article/...  \n",
       "22  https://www.sciencedirect.com/science/article/...  \n",
       "23  https://www.sciencedirect.com/science/article/...  \n",
       "24  https://www.sciencedirect.com/science/article/...  "
      ]
     },
     "execution_count": 874,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q8=requests.get('https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles')\n",
    "soup=BeautifulSoup(q8.content)\n",
    "downloads=[]\n",
    "for i in soup.find_all('h2',class_='sc-1qrq3sd-1 gRGSUS sc-1nmom32-0 sc-1nmom32-1 btcbYu goSKRg'):\n",
    "    downloads.append(i.text)\n",
    "author=[]\n",
    "for i in soup.find_all('span',class_='sc-1w3fpd7-0 dnCnAO'):\n",
    "    author.append(i.text)\n",
    "date=[]\n",
    "for i in soup.find_all('span',class_='sc-1thf9ly-2 dvggWt'):\n",
    "    date.append(i.text)\n",
    "data=soup.find_all('li',class_='sc-9zxyh7-1 sc-9zxyh7-2 kOEIEO hvoVxs')\n",
    "links=[]\n",
    "for i in data:\n",
    "    plink=i.find('a')['href']\n",
    "    links.append(plink)\n",
    "article=pd.DataFrame({'DOWNLOADS':downloads,'AUTHORS':author,'DATE':date,'LINK':links})\n",
    "article"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5ba2b5",
   "metadata": {},
   "source": [
    "# QUESTION 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f4a81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bs4\n",
    "!pip install requests\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "id": "7b189a18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>CUISINE</th>\n",
       "      <th>PRICE</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>IMAGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Castle Barbeque</td>\n",
       "      <td>Chinese, North Indian</td>\n",
       "      <td>₹ 2,000 for 2 (approx)</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jungle Jamboree</td>\n",
       "      <td>North Indian, Asian, Italian</td>\n",
       "      <td>₹ 1,680 for 2 (approx)</td>\n",
       "      <td>3CS Mall,Lajpat Nagar - 3, South Delhi</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cafe Knosh</td>\n",
       "      <td>Italian, Continental</td>\n",
       "      <td>₹ 3,000 for 2 (approx)</td>\n",
       "      <td>The Leela Ambience Convention Hotel,Shahdara, ...</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Castle Barbeque</td>\n",
       "      <td>Chinese, North Indian</td>\n",
       "      <td>₹ 2,000 for 2 (approx)</td>\n",
       "      <td>Pacific Mall,Tagore Garden, West Delhi</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Barbeque Company</td>\n",
       "      <td>North Indian, Chinese</td>\n",
       "      <td>₹ 1,700 for 2 (approx)</td>\n",
       "      <td>Gardens Galleria,Sector 38A, Noida</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>India Grill</td>\n",
       "      <td>North Indian, Italian</td>\n",
       "      <td>₹ 2,400 for 2 (approx)</td>\n",
       "      <td>Hilton Garden Inn,Saket, South Delhi</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Delhi Barbeque</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>₹ 1,800 for 2 (approx)</td>\n",
       "      <td>Taurus Sarovar Portico,Mahipalpur, South Delhi</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Monarch - Bar Be Que Village</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>₹ 1,900 for 2 (approx)</td>\n",
       "      <td>Indirapuram Habitat Centre,Indirapuram, Ghaziabad</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Indian Grill Room</td>\n",
       "      <td>North Indian, Mughlai</td>\n",
       "      <td>₹ 2,200 for 2 (approx)</td>\n",
       "      <td>Suncity Business Tower,Golf Course Road, Gurgaon</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               NAME                        CUISINE  \\\n",
       "0                   Castle Barbeque          Chinese, North Indian   \n",
       "1                   Jungle Jamboree   North Indian, Asian, Italian   \n",
       "2                        Cafe Knosh           Italian, Continental   \n",
       "3                   Castle Barbeque          Chinese, North Indian   \n",
       "4              The Barbeque Company          North Indian, Chinese   \n",
       "5                       India Grill          North Indian, Italian   \n",
       "6                    Delhi Barbeque                   North Indian   \n",
       "7  The Monarch - Bar Be Que Village                   North Indian   \n",
       "8                 Indian Grill Room          North Indian, Mughlai   \n",
       "\n",
       "                     PRICE                                           LOCATION  \\\n",
       "0  ₹ 2,000 for 2 (approx)                      Connaught Place, Central Delhi   \n",
       "1  ₹ 1,680 for 2 (approx)              3CS Mall,Lajpat Nagar - 3, South Delhi   \n",
       "2  ₹ 3,000 for 2 (approx)   The Leela Ambience Convention Hotel,Shahdara, ...   \n",
       "3  ₹ 2,000 for 2 (approx)              Pacific Mall,Tagore Garden, West Delhi   \n",
       "4  ₹ 1,700 for 2 (approx)                  Gardens Galleria,Sector 38A, Noida   \n",
       "5  ₹ 2,400 for 2 (approx)                Hilton Garden Inn,Saket, South Delhi   \n",
       "6  ₹ 1,800 for 2 (approx)      Taurus Sarovar Portico,Mahipalpur, South Delhi   \n",
       "7  ₹ 1,900 for 2 (approx)   Indirapuram Habitat Centre,Indirapuram, Ghaziabad   \n",
       "8  ₹ 2,200 for 2 (approx)    Suncity Business Tower,Golf Course Road, Gurgaon   \n",
       "\n",
       "                                               IMAGE  \n",
       "0  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "1  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "2  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "3  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "4  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "5  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "6  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "7  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "8  https://im1.dineout.co.in/images/uploads/resta...  "
      ]
     },
     "execution_count": 875,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q9=requests.get('https://www.dineout.co.in/delhi-restaurants/buffet-special')\n",
    "soup=BeautifulSoup(q9.content)\n",
    "name=[]\n",
    "for i in soup.find_all('a',class_='restnt-name ellipsis'):\n",
    "    name.append(i.text)\n",
    "cuisine=[]\n",
    "for i in soup.find_all('span',class_='double-line-ellipsis'):\n",
    "    cuisine.append(i.text.split('|')[1])\n",
    "price=[]\n",
    "for i in soup.find_all('span',class_='double-line-ellipsis'):\n",
    "    price.append(i.text.split('|')[0])\n",
    "loc=[]\n",
    "for i in soup.find_all('div',class_='restnt-loc ellipsis'):\n",
    "    loc.append(i.text)\n",
    "img=[]\n",
    "for i in soup.find_all('img',class_='no-img'):\n",
    "    img.append(i.get('data-src'))\n",
    "details=pd.DataFrame({'NAME':name,'CUISINE':cuisine,'PRICE':price,'LOCATION':loc,'IMAGE':img})\n",
    "details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64a68c8",
   "metadata": {},
   "source": [
    "# QUESTION 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b85caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bs4\n",
    "!pip install requests\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "id": "60523314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RANK</th>\n",
       "      <th>PUBLICATION</th>\n",
       "      <th>H5-INDEX</th>\n",
       "      <th>H5-MEDIUM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>Nature</td>\n",
       "      <td>444</td>\n",
       "      <td>667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>The New England Journal of Medicine</td>\n",
       "      <td>432</td>\n",
       "      <td>780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>Science</td>\n",
       "      <td>401</td>\n",
       "      <td>614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>IEEE/CVF Conference on Computer Vision and Pat...</td>\n",
       "      <td>389</td>\n",
       "      <td>627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>The Lancet</td>\n",
       "      <td>354</td>\n",
       "      <td>635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96.</td>\n",
       "      <td>Journal of Business Research</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97.</td>\n",
       "      <td>Molecular Cancer</td>\n",
       "      <td>145</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98.</td>\n",
       "      <td>Sensors</td>\n",
       "      <td>145</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99.</td>\n",
       "      <td>Nature Climate Change</td>\n",
       "      <td>144</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100.</td>\n",
       "      <td>IEEE Internet of Things Journal</td>\n",
       "      <td>144</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    RANK                                        PUBLICATION H5-INDEX H5-MEDIUM\n",
       "0     1.                                             Nature      444       667\n",
       "1     2.                The New England Journal of Medicine      432       780\n",
       "2     3.                                            Science      401       614\n",
       "3     4.  IEEE/CVF Conference on Computer Vision and Pat...      389       627\n",
       "4     5.                                         The Lancet      354       635\n",
       "..   ...                                                ...      ...       ...\n",
       "95   96.                       Journal of Business Research      145       233\n",
       "96   97.                                   Molecular Cancer      145       209\n",
       "97   98.                                            Sensors      145       201\n",
       "98   99.                              Nature Climate Change      144       228\n",
       "99  100.                    IEEE Internet of Things Journal      144       212\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 876,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q10=requests.get('https://scholar.google.com/citations?view_op=top_venues&hl=en')\n",
    "soup=BeautifulSoup(q10.content)\n",
    "rank=[]\n",
    "for i in soup.find_all('td',class_='gsc_mvt_p'):\n",
    "    rank.append(i.text)\n",
    "pub=[]\n",
    "for i in soup.find_all('td',class_='gsc_mvt_t'):\n",
    "    pub.append(i.text)\n",
    "h5=[]\n",
    "for i in soup.find_all('a',class_='gs_ibl gsc_mp_anchor'):\n",
    "    h5.append(i.text)\n",
    "h5m=[]\n",
    "for i in soup.find_all('span',class_='gs_ibl gsc_mp_anchor'):\n",
    "    h5m.append(i.text)\n",
    "google=pd.DataFrame({'RANK':rank,'PUBLICATION':pub,'H5-INDEX':h5,'H5-MEDIUM':h5m})\n",
    "google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17901e66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
